import os
import json
import sys
import random
from pathlib import Path
from openai import OpenAI
import google.generativeai as genai
from dotenv import load_dotenv

# =========================================================
# ğŸ‘¹ [ë ˆë“œíŒ€] Red Team Critic (Ultimate Version)
# ì—­í• : ë…¼ë¦¬ì  ì˜¤ë¥˜, íƒ€ì„ë¼ì¸ ëª¨ìˆœ, ê³ ì¦ ì‹¤íŒ¨ ì •ë°€ íƒ€ê²©
# ì ìš© ê¸°ë²•: ToT, CoT, RAG, Few-Shot, Self-Reflection
# =========================================================

# 1. í™˜ê²½ ë° ê²½ë¡œ ì„¤ì •
CURRENT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = CURRENT_DIR.parent

if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

load_dotenv(dotenv_path=PROJECT_ROOT / ".env")

OPENAI_KEY = os.getenv("OPENAI_API_KEY")
GEMINI_KEY = os.getenv("GEMINI_KEY_PLANNING") or os.getenv("GEMINI_API_KEY")

# í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = None
if OPENAI_KEY:
    try: client = OpenAI(api_key=OPENAI_KEY)
    except: pass

if GEMINI_KEY: genai.configure(api_key=GEMINI_KEY)

# ë°±ì—… ëª¨ë¸ ì„¤ì •
GEMINI_BACKUP_MODEL = 'gemini-1.5-pro-latest'
try:
    from model_selector import find_best_model
    GEMINI_BACKUP_MODEL = find_best_model()
except: pass

# 2. RAG ë°ì´í„° ê²½ë¡œ
RUBRIC_FILE = PROJECT_ROOT / "00_ê¸°ì¤€ì •ë³´_ë³´ë¬¼ì°½ê³ " / "standard-rubric.json"
TREND_REPORT = PROJECT_ROOT / "02_ë¶„ì„ì‹¤_Analysis" / "00_í†µí•©_íŠ¸ë Œë“œ_ë¦¬í¬íŠ¸.json"
TIP_DIR = PROJECT_ROOT / "00_ê¸°ì¤€ì •ë³´_ë³´ë¬¼ì°½ê³ " / "05_íŒ_ë³´ë¬¼ì°½ê³ "
DB_DIR = PROJECT_ROOT / "04_ì„¤ì •_ìë£Œì§‘"

# 3. [Few-Shot] ë…¼ë¦¬ì  ì˜¤ë¥˜ ì ë°œ ì˜ˆì‹œ
FEW_SHOT_CRITIQUES = """
[Case 1 - Timeline Error]
Input: "1997ë…„ 1ì›”, ì£¼ì¸ê³µì€ ìŠ¤ë§ˆíŠ¸í°ìœ¼ë¡œ ì£¼ì‹ì„ ê±°ë˜í•˜ë©°..."
Critique: "FATAL ERROR. 1997ë…„ì—ëŠ” ìŠ¤ë§ˆíŠ¸í°ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. MTSëŠ”ì»¤ë…• HTSë„ ì´ˆê¸° ë‹¨ê³„ì„. ê³ ì¦ ì‹¤íŒ¨."

[Case 2 - Causality Error]
Input: "ì£¼ì¸ê³µì´ íšŒê·€í•˜ì—¬ ê²½ìŸì‚¬ì˜ ê¸°ë°€ì„ ë¹¼ëŒë ¤ ì„ ì í–ˆë‹¤. ê·¸ëŸ°ë° ê²½ìŸì‚¬ëŠ” ì•„ë¬´ëŸ° ëŒ€ì‘ë„ í•˜ì§€ ì•Šê³  ë§í–ˆë‹¤."
Critique: "LOGIC ERROR. ë‚˜ë¹„íš¨ê³¼ ëˆ„ë½. ê²½ìŸì‚¬ê°€ ë°”ë³´ê°€ ì•„ë‹Œ ì´ìƒ ê¸°ë°€ ìœ ì¶œì— ëŒ€í•´ ë‚´ë¶€ ê°ì‚¬ë¥¼ í•˜ê±°ë‚˜ ëŒ€ì‘ ì „ëµì„ ì§°ì–´ì•¼ í•¨. ì‘ìœ„ì  ì „ê°œ."
"""

def gather_evidence():
    """
    [RAG System] ë¹„í‰ì— í•„ìš”í•œ ë²•ì „(Rubric)ê³¼ ì¦ê±°(Fact DB)ë¥¼ ìˆ˜ì§‘
    """
    rubric = RUBRIC_FILE.read_text(encoding='utf-8') if RUBRIC_FILE.exists() else "No Rubric"
    trend = TREND_REPORT.read_text(encoding='utf-8') if TREND_REPORT.exists() else "No Trend"
    
    # ì„¤ì • ìë£Œì§‘ (Historical Facts) - ë¬´ì‘ìœ„ 1ê°œ ì°¸ì¡° (í† í° ì ˆì•½)
    fact_db = ""
    if DB_DIR.exists():
        facts = list(DB_DIR.rglob("*.md")) + list(DB_DIR.rglob("*.txt"))
        if facts:
            target = random.choice(facts)
            fact_db = f"\n[Fact DB: {target.name}]\n{target.read_text(encoding='utf-8')[:3000]}\n"

    # ì‘ë²• íŒ (Logic)
    tips_data = ""
    if TIP_DIR.exists():
        tips = list(TIP_DIR.rglob("*.md"))
        if tips:
            target = random.choice(tips)
            tips_data = f"\n[Writing Tip: {target.name}]\n{target.read_text(encoding='utf-8')[:1000]}\n"
            
    return rubric, trend, tips_data, fact_db

def critique_plan(plan_json, round_num):
    """
    [Core Logic] 3ë‹¨ê³„ ì‚¬ê³  ê³¼ì •(CoT)ì„ í†µí•´ ì •ë°€ íƒ€ê²©
    """
    print(f"\nğŸ‘¹ [Red Team] ê¸°íšì•ˆ V{round_num} ê²€ì¦ í”„ë¡œì„¸ìŠ¤ ê°€ë™...")
    
    rubric, trend, tips, fact_db = gather_evidence()

    # ğŸ”¥ [Ultimate Prompt]
    prompt = f"""
    # Role (Persona)
    You are **Korea's Most Ruthless Web Novel Chief Editor**.
    You specialize in finding "Plot Holes", "Time Paradoxes", and "Lazy Writing".
    Your goal is to ensure the story is logically flawless and commercially viable.

    # RAG Context
    - **[Evaluation Rubric]**: {rubric[:1000]}
    - **[Market Trend]**: {trend[:1000]}
    - **[Fact Check DB]**: {fact_db}
    - **[Writing Standard]**: {tips}

    # Target Proposal
    {plan_json}

    # Audit Protocol (Chain of Thought & Tree of Thoughts)
    1. **Timeline Simulation**: Construct a mental timeline of the plot. Are the events physically possible? (e.g., Technology level, Historical events).
    2. **Causality Check (ReAct)**: "If Protagonist does X, World must react with Y." Did the world react realistically? Or are the enemies too dumb?
    3. **Character Consistency**: Does the protagonist's personality (MBTI/Flaw) match their actions?
    4. **Market Fit**: Compare with [Market Trend]. Is this cliche or fresh?

    # Few-Shot Examples (How to critique)
    {FEW_SHOT_CRITIQUES}

    # Output Requirement
    - Output **JSON ONLY**.
    - Language: Korean (Sharp, Critical Tone).

    # Output JSON Structure
    {{
        "score": (0-100 Integer),
        "status": "PASS" (if score >= 85) or "REJECT",
        "critique_summary": "One sentence summary of the biggest flaw.",
        "fatal_flaws": [
            "1. Timeline Error: ...",
            "2. Logic Error: ..."
        ],
        "improvement_instructions": "Specific, actionable instructions for the Planner to fix these errors."
    }}
    """

    # 1. GPT-5.1 (or 4o) ì‹œë„
    if client:
        try:
            response = client.chat.completions.create(
                model="gpt-5.1", # ì—†ëŠ” ê²½ìš° gpt-4oë¡œ ìë™ fallback ì²˜ë¦¬ í•„ìš”í•˜ë‚˜, ì—¬ê¸°ì„  ëª…ì‹œì  ì‹œë„
                messages=[
                    {"role": "system", "content": "You are a Logic Auditor. JSON Only."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3 # ë…¼ë¦¬ ê²€ì¦ì´ë¯€ë¡œ ì°½ì˜ì„±(ì˜¨ë„)ì„ ë‚®ì¶¤
            )
            return response.choices[0].message.content.strip().replace("```json", "").replace("```", "")
        except:
            # GPT-4o Fallback
            try:
                response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "system", "content": "JSON Only."}, {"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content.strip().replace("```json", "").replace("```", "")
            except: pass

    # 2. Gemini Fallback (ìµœí›„ì˜ ë³´ë£¨)
    try:
        model = genai.GenerativeModel(GEMINI_BACKUP_MODEL)
        res = model.generate_content(prompt)
        return res.text.strip().replace("```json", "").replace("```", "")
    except Exception as e:
        return json.dumps({
            "score": 0, 
            "status": "ERROR", 
            "critique_summary": f"AI Error: {str(e)}",
            "improvement_instructions": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ë¹„í‰ ë¶ˆê°€."
        })

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš©
    print("Red Team Module Loaded.")