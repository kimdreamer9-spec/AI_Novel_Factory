import os
import re
import json
import time
import warnings
from pathlib import Path
import google.generativeai as genai
from dotenv import load_dotenv

# =========================================================
# âš™ï¸ [ê°€ê³µ íŒ€] Processor Pro (Pure OCR Edition)
# ì—­í• : ì´ë¯¸ì§€ -> í…ìŠ¤íŠ¸ ë³€í™˜ -> í™”ìˆ˜ ë¶„í•  (ë¶„ì„ ê¸°ëŠ¥ ì œê±°ë¨)
# =========================================================

warnings.filterwarnings("ignore")
load_dotenv()

# 1. API í‚¤ í™•ì¸
API_KEY = os.getenv("GEMINI_KEY_PLANNING")
if not API_KEY:
    print("âŒ [ì˜¤ë¥˜] .env íŒŒì¼ì—ì„œ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

genai.configure(api_key=API_KEY)

# ---------------------------------------------------------
# ğŸ¤– [ì—”ì§„ ìë™ ë°°ì°¨] ë³µì¡í•œ ëª¨ë¸ëª… ê³ ë¯¼ ë. ë˜ëŠ” ê±° ì•Œì•„ì„œ ì¡ìŒ.
# ---------------------------------------------------------
def auto_select_model():
    print("\nğŸ” [ì‹œìŠ¤í…œ] ì‚¬ìš© ê°€ëŠ¥í•œ AI ì—”ì§„ì„ íƒìƒ‰í•©ë‹ˆë‹¤...")
    try:
        available_models = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                name = m.name.replace("models/", "")
                available_models.append(name)
        
        # ìš°ì„ ìˆœìœ„: Pro(ê³ ì„±ëŠ¥) > Flash(ê³ ì†) > ì•„ë¬´ê±°ë‚˜
        best_model = None
        
        # 1. Pro ê³„ì—´ íƒìƒ‰ (ì •í™•ë„ ìµœìš°ì„ )
        for m in available_models:
            if 'pro' in m.lower() and 'vision' not in m.lower(): # vision ì „ìš© ì œì™¸
                 best_model = m
                 break
        
        # 2. ì—†ìœ¼ë©´ Flash ê³„ì—´
        if not best_model:
            for m in available_models:
                if 'flash' in m.lower():
                    best_model = m
                    break
                    
        # 3. ì • ì—†ìœ¼ë©´ ëª©ë¡ì˜ ì²« ë²ˆì§¸
        if not best_model and available_models:
            best_model = available_models[0]
            
        if not best_model:
             print("âŒ [ì¹˜ëª…ì  ì˜¤ë¥˜] ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
             exit()

        print(f"   âœ… [ì—”ì§„ í™•ì •] '{best_model}' ëª¨ë¸ë¡œ ê°€ë™í•©ë‹ˆë‹¤.")
        return genai.GenerativeModel(best_model)

    except Exception as e:
        print(f"âŒ [ì¹˜ëª…ì  ì˜¤ë¥˜] ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        exit()

# ì—”ì§„ ì‹œë™
model = auto_select_model()
BASE_DIR = Path.cwd()

# ê°ì‹œ ê²½ë¡œ ì„¤ì •
REALTIME_ROOT = BASE_DIR / "99_ì‹¤ì‹œê°„_ì‘ì—…ë°©"
MANUAL_ROOT = BASE_DIR / "01_ìë£Œì‹¤_Raw_Data"
OUTPUT_ROOT = BASE_DIR / "01_ìë£Œì‹¤_Raw_Data" / "00_ì„±ê³µì‘_ì•„ì¹´ì´ë¸Œ"

def natural_sort_key(s):
    return [int(text) if text.isdigit() else text.lower()
            for text in re.split('([0-9]+)', str(s))]

def ocr_images(image_paths, novel_title):
    full_text = ""
    total_imgs = len(image_paths)
    print(f"      ğŸ“¸ [OCR] ì´ë¯¸ì§€ {total_imgs}ì¥ ë³€í™˜ ì‹œì‘...")
    
    batch_size = 10
    for i in range(0, total_imgs, batch_size):
        batch = image_paths[i:i+batch_size]
        
        # [í”„ë¡¬í”„íŠ¸] ì˜¤ì§ í…ìŠ¤íŠ¸ ì¶”ì¶œì—ë§Œ ì§‘ì¤‘
        prompt = """
        ì´ë¯¸ì§€ì˜ ì†Œì„¤ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œë§Œ ì¶”ì¶œí•´.
        [ì ˆëŒ€ ê·œì¹™]
        1. '< 001 : ì œëª© >' ê°™ì€ íšŒì°¨ êµ¬ë¶„ìëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ìœ ì§€í•  ê²ƒ.
        2. UI, ì‹œê°„, ë°°í„°ë¦¬ ê°™ì€ ì¡ë‹¤í•œ ì •ë³´ëŠ” ì‚­ì œí•  ê²ƒ.
        3. ë¶„ì„í•˜ì§€ ë§ê³  ìˆëŠ” ê·¸ëŒ€ë¡œ ê¸€ìë§Œ ì˜®ê¸¸ ê²ƒ.
        """
        
        try:
            img_objects = []
            for img_path in batch:
                img_data = Path(img_path).read_bytes()
                img_objects.append({'mime_type': 'image/png', 'data': img_data})
            
            # íƒ€ì„ì•„ì›ƒ ë„‰ë„‰í•˜ê²Œ
            response = model.generate_content([prompt, *img_objects], request_options={'timeout': 90})
            if response.text:
                full_text += response.text + "\n\n"
            
            print(f"         ... {min(i+batch_size, total_imgs)}/{total_imgs} ì™„ë£Œ")
            time.sleep(1) # API ë³´í˜¸
            
        except Exception as e:
            print(f"      ğŸš¨ ë³€í™˜ ì‹¤íŒ¨(êµ¬ê°„ {i}): {e}")
            
    return full_text

def split_episodes(full_text, novel_title):
    # <...>, [...] íŒ¨í„´ìœ¼ë¡œ íšŒì°¨ ë‚˜ëˆ„ê¸°
    split_pattern = r"(?:<|\[)[^>\]]*(?:\d+|í™”|í”„ë¡¤ë¡œê·¸|ì—í•„ë¡œê·¸)[^>\]]*(?:>|\])"
    matches = list(re.finditer(split_pattern, full_text))
    
    if not matches:
        # êµ¬ë¶„ì ì—†ìœ¼ë©´ í†µíŒŒì¼ 1ê°œ ìƒì„±
        return [(f"{novel_title}_í†µí•©ë³¸.md", full_text)]

    results = []
    for i in range(len(matches)):
        start_idx = matches[i].start()
        end_idx = matches[i+1].start() if i + 1 < len(matches) else len(full_text)
        
        chunk = full_text[start_idx:end_idx].strip()
        
        # íŒŒì¼ëª… ìƒì„± (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        title_raw = matches[i].group().strip()
        safe_title = re.sub(r'[\\/*?:"<>|\[\]]', "", title_raw).strip()
        filename = f"{novel_title}_{i+1:03d}_{safe_title}.md"
        results.append((filename, chunk))
        
    return results

def process_novels():
    print("\nğŸ­ [ê³µì¥ ê°€ë™] ë‹¨ìˆœ ê°€ê³µ ëª¨ë“œ (OCR -> MD)")
    
    target_dirs = []

    # 1. ì‹¤ì‹œê°„ ì‘ì—…ë°© (SCAN_COMPLETE íŒŒì¼ í™•ì¸)
    if REALTIME_ROOT.exists():
        for d in REALTIME_ROOT.iterdir():
            if d.is_dir() and (d / "SCAN_COMPLETE").exists():
                print(f"âš¡ [ëŒ€ê¸°ì—´] ì‹¤ì‹œê°„ ìŠ¤ìº”ë³¸: {d.name}")
                target_dirs.append(d)

    # 2. ìˆ˜ë™ íˆ¬ì…êµ¬ (99_ë¡œ ì‹œì‘í•˜ëŠ” í´ë” í™•ì¸)
    if MANUAL_ROOT.exists():
        for d in MANUAL_ROOT.iterdir():
            if d.is_dir() and d.name.startswith("99_"):
                for sub_d in d.iterdir():
                    if sub_d.is_dir():
                        target_dirs.append(sub_d)

    if not target_dirs:
        print("âŒ ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    for novel_dir in target_dirs:
        print(f"\nğŸ“˜ [ì‘ì—… ì‹œì‘] {novel_dir.name}")
        
        images = []
        for ext in ["*.png", "*.jpg", "*.jpeg", "*.ZK", "*.zk"]:
            images.extend(list(novel_dir.glob(ext)))
            images.extend(list(novel_dir.glob(ext.upper())))
        images.sort(key=natural_sort_key)
        
        if not images:
            print(f"      âš ï¸ í´ë”ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            continue
        
        # [ë³€ê²½] ì¥ë¥´ ë¶„ì„ API ì œê±° -> ìŠ¤ìºë„ˆê°€ ì¤€ íŒŒì¼ ì“°ê±°ë‚˜ 'ìˆ˜ë™' ì²˜ë¦¬
        genre = "ë¯¸ë¶„ë¥˜_ìˆ˜ë™"
        if (novel_dir / "genre.txt").exists():
            genre = (novel_dir / "genre.txt").read_text(encoding='utf-8').strip()
            # ë²ˆí˜¸í‘œ ì œê±° (01_ì¬ë²Œë¬¼ -> ì¬ë²Œë¬¼)
            genre = genre.split("_")[-1] if "_" in genre else genre
        
        print(f"      ğŸ·ï¸ ë¶„ë¥˜: {genre}")

        # 1. OCR ì‹¤í–‰
        text = ocr_images(images, novel_dir.name)
        if not text: continue

        # 2. ìª¼ê°œê¸°
        episodes = split_episodes(text, novel_dir.name)
        
        # 3. ì €ì¥
        save_dir = OUTPUT_ROOT / genre / novel_dir.name
        save_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"      ğŸ’¾ ì €ì¥ ì¤‘... ({len(episodes)}ê°œ íŒŒì¼)")
        for fname, content in episodes:
            (save_dir / fname).write_text(content, encoding='utf-8')
        
        # ë©”íƒ€ ì •ë³´ ê»ë°ê¸° (ë‚˜ì¤‘ì— ì±„ìš¸ ìš©ë„)
        if not (save_dir / f"{novel_dir.name}_meta.json").exists():
            (save_dir / f"{novel_dir.name}_meta.json").write_text(
                json.dumps({"title": novel_dir.name, "genre": genre}, indent=4, ensure_ascii=False), encoding='utf-8'
            )

        # ì‹¤ì‹œê°„ ì‘ì—…ë°© ì •ë¦¬ (ì´ë¦„ ë³€ê²½)
        if "99_ì‹¤ì‹œê°„_ì‘ì—…ë°©" in str(novel_dir):
            try:
                novel_dir.rename(novel_dir.parent / f"_DONE_{novel_dir.name}")
                print("      ğŸ§¹ ì‘ì—… ì™„ë£Œ íƒœê·¸ ë¶€ì°©")
            except: pass
            
        print("      âœ… ì™„ë£Œ")

    print("\nğŸ‰ ëª¨ë“  ë³€í™˜ ì‘ì—… ë.")

if __name__ == "__main__":
    process_novels()