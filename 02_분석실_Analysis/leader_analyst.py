import os
import json
import re
import sys
import glob
from pathlib import Path
from openai import OpenAI
import google.generativeai as genai
from dotenv import load_dotenv

# =========================================================
# ðŸŽ–ï¸ [ë¶„ì„ íŒ€ìž¥] Leader Analyst (V7. No More 1.5)
# ì—­í• : Gemini(ìžë£Œì·¨í•©/ì´ˆì•ˆ) -> OpenAI(ì •ë°€íƒ€ê²©/ìµœì¢…ë³¸)
# ì—”ì§„: Gemini ìµœê°• ëª¨ë¸ (via Selector) + GPT-5.1
# =========================================================

# 1. í™˜ê²½ ë° ê²½ë¡œ ì„¤ì • (ì—„ê²© ëª¨ë“œ)
CURRENT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = CURRENT_DIR.parent  # í•œ ë‹¨ê³„ ìœ„(Root)ê°€ í”„ë¡œì íŠ¸ ë£¨íŠ¸

# ðŸ”¥ [ê²½ë¡œ ìˆ˜ì •] ë£¨íŠ¸ í´ë”ë¥¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ìµœìš°ì„  ì¶”ê°€
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

# .env ë¡œë“œ
load_dotenv(dotenv_path=PROJECT_ROOT / ".env")

GEMINI_KEY = os.getenv("GEMINI_KEY_PLANNING")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")

if not GEMINI_KEY or not OPENAI_KEY:
    print("âŒ [Fatal] API í‚¤ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. .envë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)

genai.configure(api_key=GEMINI_KEY)
client = OpenAI(api_key=OPENAI_KEY)

# ðŸ”¥ [í•µì‹¬] 1.5 íƒ€ë ¹ ê¸ˆì§€ -> ë¬´ì¡°ê±´ Selectorì—ê²Œ ìœ„ìž„
try:
    from model_selector import analyze_and_select_model
    
    # ë¶„ì„ìš©(Analyst)ìœ¼ë¡œ ê°€ìž¥ ë˜‘ë˜‘í•œ ë†ˆì„ í˜¸ì¶œ (Deep-Research or 3.0 Pro)
    GEMINI_MODEL_NAME = analyze_and_select_model(role='analyst')
    print(f"ðŸš€ [Leader Engine] Gemini ë¶„ì„ê°€: {GEMINI_MODEL_NAME}")
    
    gemini_model = genai.GenerativeModel(GEMINI_MODEL_NAME)

except ImportError:
    print("âŒ [ì¹˜ëª…ì  ì˜¤ë¥˜] ë£¨íŠ¸ í´ë”ì— 'model_selector.py'ê°€ ì—†ìŠµë‹ˆë‹¤!")
    print(f"   íƒìƒ‰ ê²½ë¡œ: {PROJECT_ROOT}")
    sys.exit(1) # 1.5 ì“°ëŠë‹ˆ ì°¨ë¼ë¦¬ ì¢…ë£Œí•¨
except Exception as e:
    print(f"âŒ [ì¹˜ëª…ì  ì˜¤ë¥˜] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    sys.exit(1)


# ê²½ë¡œ ì„¤ì •
ANALYSIS_DIR = PROJECT_ROOT / "02_ë¶„ì„ì‹¤_Analysis"
OUTPUT_FILE = ANALYSIS_DIR / "00_í†µí•©_íŠ¸ë Œë“œ_ë¦¬í¬íŠ¸.json"
RUBRIC_FILE = PROJECT_ROOT / "00_ê¸°ì¤€ì •ë³´_ë³´ë¬¼ì°½ê³ " / "standard-rubric.json"

# ---------------------------------------------------------
# ðŸ† [Golden Example] íŒ€ìž¥ì´ ë§Œë“¤ì–´ì•¼ í•  ì´ìƒì ì¸ ê²°ê³¼ë¬¼
# ---------------------------------------------------------
GOLDEN_REPORT_EXAMPLE = """
{
    "trend_version": "2026_Trend_Analysis",
    "winning_formula": {
        "core_philosophy": "Reader Dopamine First. No slow build-up. Instant gratification via competence.",
        "style_guideline": "Short sentences (under 50 chars). Dialogue driven (60%+). Focus on sensory details of wealth and power."
    },
    "character_constitution": {
        "protagonist_archetype": "The 'System-Audit Expert' or 'Vengeful Regressor'. Must have a clear 'Lack' (poverty, betrayal) and a 'Cheat' (Future Knowledge/System).",
        "villain_archetype": "The 'Arrogant Establishment'. Must be annoying but logically defeatable.",
        "role_distribution": "MC (80%), Villain (10%), Supporters (10%)."
    },
    "plot_structure_law": {
        "hook_rule": "Ep 1 must end with a 'Life-or-Death' crisis or a 'Game-Changing' reward.",
        "pacing_rule": "One conflict and resolution every 3000 characters (Cider loop)."
    }
}
"""

# ---------------------------------------------------------
# ðŸ§  [Step 1] Gemini: ìžë£Œ ì·¨í•© ë° ì´ˆì•ˆ ìž‘ì„± (ToT)
# ---------------------------------------------------------
def step1_gather_and_draft(rubric, styles, chars, stories):
    print(f"   ðŸ§  [Gemini ({GEMINI_MODEL_NAME})] ëª¨ë“  ë³´ê³ ì„œë¥¼ ì½ê³  ì´ˆì•ˆì„ ìž‘ì„±í•©ë‹ˆë‹¤...")
    
    prompt = f"""
    # Role
    You are a **Senior Web Novel Trend Researcher**.
    Your task is to read all these field reports (Style, Character, Story) and extract the **'Common Success Factors'**.

    # Context (RAG)
    [Rubric]: {rubric[:1000]}
    [Style Reports]: {styles[:50000]} 
    [Character Reports]: {chars[:50000]}
    [Story Reports]: {stories[:50000]}

    # Task: Draft a Trend Summary
    Don't just summarize. Find the **Intersection** of all successful works.
    
    # Process (Tree of Thoughts)
    1. **Pattern A (Characters)**: What do all Protagonists have in common? (e.g., Are they all regressors?)
    2. **Pattern B (Pacing)**: How fast is the story? (e.g., Fast hook in Ep 1?)
    3. **Pattern C (Tone)**: Is it serious or light?
    
    # Output
    Summarize these patterns into a detailed text draft.
    """
    try:
        res = gemini_model.generate_content(prompt)
        return res.text
    except Exception as e:
        print(f"   âŒ Gemini ì´ˆì•ˆ ìž‘ì„± ì‹¤íŒ¨: {e}")
        return None

# ---------------------------------------------------------
# âš–ï¸ [Step 2] OpenAI: ìµœì¢… ì •ì œ ë° ê·œê²©í™” (Self-Reflection)
# ---------------------------------------------------------
def step2_finalize_report(draft):
    print("   âš–ï¸ [OpenAI GPT-5.1] ì´ˆì•ˆì„ ê²€ìˆ˜í•˜ê³  'í•„ìŠ¹ ê³µì‹'ì„ í™•ì •í•©ë‹ˆë‹¤...")
    
    prompt = f"""
    # Role
    You are the **Chief Editor (Final Decision Maker)**.
    Convert the researcher's draft into a strict **'Winning Formula JSON'** for the Writer AI.

    # Input Data (Draft)
    {draft}

    # Golden Example (Follow this format & depth)
    {GOLDEN_REPORT_EXAMPLE}

    # Execution Protocol (Self-Reflection)
    1. **Critique**: Is the draft too vague? (e.g., "Write well" -> Reject).
    2. **Refine**: Change it to specific instructions (e.g., "Sentences must be < 40 chars").
    3. **Finalize**: Output the JSON strictly.

    # Output Format (JSON Only)
    Produce the JSON structure defined in the Golden Example.
    """
    
    try:
        # GPT-5.1 í˜¸ì¶œ (ì—†ìœ¼ë©´ 4o í´ë°±)
        model_name = "gpt-5.1"
        try:
            response = client.chat.completions.create(
                model=model_name, 
                messages=[
                    {"role": "system", "content": "You are a strict logic machine. Output JSON only."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2
            )
        except:
            print("      âš ï¸ [Info] GPT-5.1 í˜¸ì¶œ ì‹¤íŒ¨, gpt-4oë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            model_name = "gpt-4o"
            response = client.chat.completions.create(
                model=model_name, 
                messages=[{"role": "system", "content": "JSON only."}, {"role": "user", "content": prompt}],
                temperature=0.2
            )
        
        # ðŸ”¥ [ì•ˆì „ ìž¥ì¹˜] ì •ê·œì‹ì„ ì‚¬ìš©í•˜ì—¬ JSONë§Œ ì¶”ì¶œ (AIê°€ ìž¡ë‹´ì„ ì„žì„ ê²½ìš° ëŒ€ë¹„)
        content = response.choices[0].message.content
        match = re.search(r'\{.*\}', content, re.DOTALL)
        if match:
            return match.group(0)
        else:
            return content.replace("```json", "").replace("```", "").strip()

    except Exception as e:
        print(f"   âŒ OpenAI ì •ì œ ì‹¤íŒ¨: {e}")
        return None

# ---------------------------------------------------------
# ðŸ”¥ ë©”ì¸ ì‹¤í–‰ ë¡œì§
# ---------------------------------------------------------
def run_leader():
    print(f"\nðŸŽ–ï¸ [Leader Analyst] í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹œìŠ¤í…œ ê°€ë™...")
    
    # 1. íŒŒì¼ ì½ê¸° (rglobìœ¼ë¡œ í•˜ìœ„ í´ë”ê¹Œì§€ íƒìƒ‰!)
    rubric_text = "No Rubric"
    if RUBRIC_FILE.exists(): rubric_text = RUBRIC_FILE.read_text(encoding='utf-8')

    # í•˜ìœ„ í´ë”ì˜ ëª¨ë“  JSON ìˆ˜ì§‘
    styles = []
    chars = []
    stories = []
    
    for f in ANALYSIS_DIR.rglob("STYLE_*.json"):
        try: styles.append(f.read_text(encoding='utf-8'))
        except: pass
        
    for f in ANALYSIS_DIR.rglob("CHAR_*.json"):
        try: chars.append(f.read_text(encoding='utf-8'))
        except: pass
        
    for f in ANALYSIS_DIR.rglob("STORY_*.json"):
        try: stories.append(f.read_text(encoding='utf-8'))
        except: pass

    if not (styles or chars or stories):
        print("âŒ [ì˜¤ë¥˜] ë¶„ì„í•  ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤. master_analyst.pyê°€ ì œëŒ€ë¡œ ëŒì•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        print(f"   íƒìƒ‰ ê²½ë¡œ: {ANALYSIS_DIR}")
        return

    print(f"   ðŸ“‚ ë¶„ì„ ëŒ€ìƒ: ì´ {len(styles) + len(chars) + len(stories)}ê°œì˜ ë³´ê³ ì„œ (í•˜ìœ„ í´ë” í¬í•¨)")

    # 2. Step 1: Gemini ì´ˆì•ˆ
    draft = step1_gather_and_draft(rubric_text, str(styles), str(chars), str(stories))
    if not draft: return

    # 3. Step 2: OpenAI ìµœì¢…ë³¸
    final_json = step2_finalize_report(draft)
    
    if final_json:
        # 4. ì €ìž¥
        try:
            # JSON ìœ íš¨ì„± ê²€ì‚¬
            json.loads(final_json)
            OUTPUT_FILE.write_text(final_json, encoding='utf-8')
            print(f"   ðŸŽ‰ [ì„±ê³µ] í†µí•© íŠ¸ë Œë“œ ë¦¬í¬íŠ¸ ë°œí–‰ ì™„ë£Œ!")
            print(f"      ðŸ“„ íŒŒì¼ ê²½ë¡œ: {OUTPUT_FILE}")
        except:
            print("   âš ï¸ [ê²½ê³ ] JSON í˜•ì‹ì´ ê¹¨ì¡ŒìŠµë‹ˆë‹¤. ì›ë³¸ í…ìŠ¤íŠ¸ë¡œ ì €ìž¥í•©ë‹ˆë‹¤.")
            OUTPUT_FILE.write_text(final_json, encoding='utf-8')

if __name__ == "__main__":
    run_leader()