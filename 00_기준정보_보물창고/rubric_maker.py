import os
import json
import sys
import re
import warnings
from pathlib import Path
from openai import OpenAI
import google.generativeai as genai
from dotenv import load_dotenv

# =========================================================
# âš–ï¸ [ê¸°ì¤€ì •ë³´ íŒ€] Rubric Maker (V7. Pure & Strict)
# ì—­í• : ì‚¬ì¥ë‹˜ì˜ ë¹„ê¸‰(Tips)ì„ ë¶„ì„í•˜ì—¬ 'ì ˆëŒ€ ë²•ì „(Rubric)'ì„ í¸ì°¬í•¨.
# ì—”ì§„: Gemini (via Selector Only) + GPT-5.1
# =========================================================

warnings.filterwarnings("ignore")

# 1. í™˜ê²½ ì„¤ì • ë° í‚¤ ë¡œë“œ
CURRENT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = CURRENT_DIR.parent
load_dotenv(dotenv_path=PROJECT_ROOT / ".env")

GEMINI_KEY = os.getenv("GEMINI_KEY_PLANNING")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")

if not GEMINI_KEY or not OPENAI_KEY:
    print("âŒ [ì˜¤ë¥˜] API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)

genai.configure(api_key=GEMINI_KEY)
client = OpenAI(api_key=OPENAI_KEY)

OUTPUT_FILE = CURRENT_DIR / "standard-rubric.json"

# ğŸ”¥ [ê²½ë¡œ ìˆ˜ì •] ë£¨íŠ¸ í´ë”ë¥¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ìµœìš°ì„  ì¶”ê°€
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

# ğŸ”¥ [í•µì‹¬] 1.5 íƒ€ë ¹ ê¸ˆì§€ -> ë¬´ì¡°ê±´ Selectorì—ê²Œ ìœ„ì„
try:
    from model_selector import find_best_model
    # ë¶„ì„ìš©(Analyst)ìœ¼ë¡œ ê°€ì¥ ë˜‘ë˜‘í•œ ë†ˆì„ í˜¸ì¶œ
    GEMINI_MODEL_NAME = find_best_model() 
    print(f"ğŸš€ [Rubric Engine] Gemini ë¶„ì„ê°€: {GEMINI_MODEL_NAME}")
    gemini_model = genai.GenerativeModel(GEMINI_MODEL_NAME)

except ImportError:
    print("âŒ [ì¹˜ëª…ì  ì˜¤ë¥˜] ë£¨íŠ¸ í´ë”ì— 'model_selector.py'ê°€ ì—†ìŠµë‹ˆë‹¤!")
    sys.exit(1) # 1.5 ì“°ëŠë‹ˆ ì°¨ë¼ë¦¬ ì¢…ë£Œí•¨
except Exception as e:
    print(f"âŒ [ì¹˜ëª…ì  ì˜¤ë¥˜] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    sys.exit(1)


# ---------------------------------------------------------
# ğŸ§  [ì‹¤í–‰] ë²•ì „ í¸ì°¬ í”„ë¡œì„¸ìŠ¤
# ---------------------------------------------------------
def create_rubric():
    print("\nâš–ï¸ [Rubric Maker] ì ˆëŒ€ ë²•ì „ í¸ì°¬ ì‹œì‘...")
    
    # 2. ìë£Œ ìˆ˜ì§‘ (íŒ ë³´ë¬¼ì°½ê³  í„¸ê¸°)
    print("   ğŸ•µï¸ [Gemini Analyst] ì‚¬ì¥ë‹˜ì˜ ë¹„ê¸‰(Tips)ì„ ì •ë°€ ë…í•´í•©ë‹ˆë‹¤...")
    all_tips = ""
    found_files = []
    
    # í˜„ì¬ í´ë”(00_ê¸°ì¤€ì •ë³´_ë³´ë¬¼ì°½ê³ ) ë° í•˜ìœ„ í´ë”ì˜ ëª¨ë“  txt, md íŒŒì¼ ìˆ˜ì§‘
    for f in CURRENT_DIR.rglob("*"):
        if f.suffix in [".txt", ".md"] and f.name not in ["rubric_maker.py", "standard-rubric.json", "requirements.txt"]:
            found_files.append(f)

    if not found_files:
        print("   âŒ ì½ì„ íŒŒì¼(íŒ)ì´ ì—†ìŠµë‹ˆë‹¤. '05_íŒ_ë³´ë¬¼ì°½ê³ 'ì— ë¹„ê¸‰ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        return

    for f in found_files:
        try:
            content = f.read_text(encoding='utf-8')
            all_tips += f"\n--- Tip Source: {f.name} ---\n{content}\n"
            print(f"      ğŸ“– Input: {f.name}")
        except: pass

    # 3. Gemini: ì‹¬ì¸µ ë¶„ì„ (ToT ê¸°ë²• ì ìš©)
    print(f"\n   ğŸ§  [Gemini ({GEMINI_MODEL_NAME})] ì„±ê³µ ìš”ì¸ ì¶”ì¶œ ì¤‘ (Tree of Thoughts)...")
    
    analysis_prompt = f"""
    You are an elite **Web Novel Trend Analyst**.
    Your task is to extract the **'Unwritten Rules of Success'** from the provided [Writing Tips].
    
    # ğŸŒ³ Tree of Thoughts Protocol (Think in 3 Branches)
    
    **Branch 1: Market Logic (Commerciality)**
    - What drives readers to pay? (e.g., Cliffhangers, Sizzling Tropes, Regressions)
    - Key Insight: Identify the 'Dopamine Triggers'.
    
    **Branch 2: Emotional Logic (Character)**
    - Why do readers love characters? (e.g., Misunderstanding, Competence, Lack)
    - Key Insight: Define the 'Fatal Flaw' and 'Charm'.
    
    **Branch 3: Structural Logic (Pacing)**
    - How fast should the plot move? (e.g., Cider every 3 eps, Hook every end)
    - Key Insight: The 'Rhythm of Satisfaction'.
    
    # Task
    Synthesize these 3 branches into a comprehensive report on **"What makes a Web Novel Sell in 2026?"**.
    Focus on specific keywords found in the [Data].
    
    [Data]
    {all_tips[:100000]}
    """
    
    try:
        analysis_res = gemini_model.generate_content(analysis_prompt)
        core_values = analysis_res.text
        print("      âœ… ë¶„ì„ ì™„ë£Œ. ë°ì´í„° ì¶”ì¶œ ì„±ê³µ.")
    except Exception as e:
        print(f"   âŒ Gemini ë¶„ì„ ë‹¨ê³„ ì‹¤íŒ¨: {e}")
        return

    # 4. OpenAI: ë²•ì „ ì œì • (Self-Reflection ê¸°ë²• ì ìš©)
    # ğŸ”¥ [ì—…ê·¸ë ˆì´ë“œ] GPT-5.1 í˜¸ì¶œ
    print("\n   âš–ï¸ [OpenAI GPT-5.1] ìµœì¢… ë²•ì „(Rubric) ì œì • ì¤‘ (Self-Reflection)...")
    
    legislator_prompt = f"""
    You are the **Supreme Legislator of Web Novels**.
    Your mission is to codify the Analyst's report into the **'Ultimate Evaluation Rubric' (JSON)**.
    
    # ğŸ§  Self-Reflection Protocol
    1. **Draft**: Create initial criteria based on the report.
    2. **Critique**: 
       - "Is 'Good Character' too vague?" -> Change to "Character acts on clear Desire & Lack".
       - "Is 'Fast Paced' ambiguous?" -> Change to "Major event occurs every 2 episodes".
    3. **Finalize**: Output the strictly defined JSON.
    
    # ğŸ›¡ï¸ Input Report
    {core_values}
    
    # ğŸ“ Output Requirement (JSON Keys)
    Create a JSON with exactly these 4 keys: 
    - "Commerciality" (Market fit, Title, Keywords)
    - "Character" (Agency, Charm, Villain)
    - "Plot_Pacing" (Cider frequency, Sweet potato limit)
    - "Episode_Hook" (Cliffhangers, Endings)
    
    Each key must have:
    - "score_1_description": What makes it fail?
    - "score_5_description": What makes it average?
    - "score_10_description": What makes it a Masterpiece?
    
    RETURN JSON ONLY.
    """
    
    try:
        # GPT-5.1 í˜¸ì¶œ (ì—†ìœ¼ë©´ 4oë¡œ í´ë°±)
        model_name = "gpt-5.1"
        try:
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "You are a cold-blooded logic machine. Output JSON only."},
                    {"role": "user", "content": legislator_prompt}
                ],
                temperature=0.2
            )
        except:
            print("      âš ï¸ [Info] GPT-5.1 í˜¸ì¶œ ì‹¤íŒ¨, gpt-4oë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            model_name = "gpt-4o"
            response = client.chat.completions.create(
                model=model_name,
                messages=[{"role": "system", "content": "JSON only."}, {"role": "user", "content": legislator_prompt}],
                temperature=0.2
            )
        
        # ğŸ”¥ [ì•ˆì „ ì¥ì¹˜] ì •ê·œì‹ìœ¼ë¡œ JSONë§Œ ì¶”ì¶œ
        content = response.choices[0].message.content
        match = re.search(r'\{.*\}', content, re.DOTALL)
        if match:
            rubric_json = match.group(0)
        else:
            rubric_json = content.replace("```json", "").replace("```", "").strip()
        
        # ìœ íš¨ì„± ê²€ì‚¬
        json.loads(rubric_json)
        
        OUTPUT_FILE.write_text(rubric_json, encoding='utf-8')
        print(f"\n   ğŸ‰ [ì™„ë£Œ] ì ˆëŒ€ ë²•ì „ 'standard-rubric.json' ì œì • ì™„ë£Œ.")
        print(f"      ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {OUTPUT_FILE}")
        
    except Exception as e:
        print(f"   âŒ OpenAI ë²•ì „ ì œì • ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    create_rubric()